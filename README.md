# French Administrative FAQ Chatbot with LoRA-tuned Mistral-7B

## Overview

This project delivers a bilingual AI assistant tailored to answer French administrative questions using a hybrid approach that combines:

- **Semantic FAQ retrieval** via multilingual sentence embeddings  
- **Natural language generation** using a fine-tuned Mistral-7B-Instruct model with LoRA adapters

### Capabilities

1. Recognize and reply to predefined FAQs with high accuracy  
2. Handle rephrased or semantically similar queries using cosine similarity  
3. Fall back to generative answers via a LoRA-tuned language model  
4. Detect and respond to small-talk or greetings

## Technical Stack

- **Base Model**: Mistral-7B-Instruct-v0.1  
- **Fine-Tuning**: LoRA (Low-Rank Adaptation)  
- **Retrieval**: Sentence Transformers (`distiluse-base-multilingual-cased-v1`)  
- **Generation**: Transformers with CPU/GPU fallback  
- **Quantization**: 4-bit inference via `bitsandbytes` (GPU only)  
- **Fallback**: Full FP32 CPU inference for low-resource machines

## Features

- âœ… GPU & CPU support with auto-detection  
- âœ… Efficient 4-bit quantized generation on GPU  
- âœ… Fully localized for French administrative content  
- âœ… Modular codebase: `core.py`, `faq.json`, adapter folders  
- âœ… Easily extensible and production-ready

## Use Cases

- Public service virtual agents (CAF, CPAM, URSSAF)  
- Local government helpdesks  
- Fine-tuning pipelines (LoRA/QLoRA)  
- French NLP/NLU experimentation


## ğŸ–¼ï¸ Demo

![Chatbot Demo](assets/example.jpg)

> ğŸ’¡ Add a screenshot or GIF of your Gradio interface here.


---

## ğŸ—‚ï¸ Repository Structure

```
fr-admin-chatbot/
â”œâ”€â”€ app.py             # Gradio-based UI
â”œâ”€â”€ core.py            # Semantic search logic + LLM fallback
â”œâ”€â”€ data/              # Contains precomputed embeddings and source FAQs
â”œâ”€â”€ models/            # Optional fallback LLM model directory
â”œâ”€â”€ requirements.txt   # Required dependencies
â””â”€â”€ README.md
```

---

##  How to Run

1. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

2. **(Optional) Use a virtual environment**

   ```bash
   python -m venv venv
   source venv/bin/activate  # Windows: venv\Scripts\activate
   ```

3. **Start the chatbot UI**

   ```bash
   python main.py
   ```


---

## ğŸ” How It Works

1. User inputs a question in French.
2. The system computes the semantic similarity to a curated FAQ dataset using `sentence-transformers`.
3. If a high-confidence match is found, the corresponding answer is returned.
4. If not, the system forwards the query to the fallback LLM (fine-tuned on administrative data) to generate a response.

---

## ğŸ§  Fallback Model

This project integrates the custom fine-tuned LLM from [`fr-admin-llm`](https://github.com/kamiyarnazari/fr-admin-llm) when retrieval fails. You can also swap it for any Hugging Face-compatible model.

---

## ğŸ“ Notes

- The FAQ data is based on official French administrative sources.
- Embeddings are precomputed for faster runtime response.
- You can plug in your own dataset or fallback model via `core.py`.

---


